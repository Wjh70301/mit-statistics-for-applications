{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the following distributions, compute the maximum likelihood estimator, and the Fisher information, if it is well defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "3e74754b-8f26-4293-8312-2d37e375deb5"
    }
   },
   "source": [
    "# 1. Bernoulii distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maximum likelihood estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "probability mass function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\mathbb{P}_p[X=x] = p^x(1-p)^{1-x}, \\;\\;\\;  x \\in \\{0, 1\\}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likelihood:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "L &= \\prod_{i=1}^n P[X=X_i] \\\\\n",
    "&= \\prod_{i=1}^np^{X_i}(1-p)^{1-X_i}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log-likelihood:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\ell &= \\log L \\\\\n",
    "&=\\sum_{i=1}^n X_i \\log p + (1-X_i)\\log(1-p) \\\\\n",
    "&=\\log p\\sum_{i=1}^n X_i +n\\log(1-p) -\\log(1-p)\\sum_{i=1}^nX_i \\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take derivative of log-likelihood w.s.t. $p$,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\frac{d \\ell}{d p} \n",
    "&= \\frac{1}{p}\\sum_{i=1}^n X_i - \\frac{n}{1-p} + \\frac{1}{1-p}\\sum_{i=1}^nX_i\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set $\\frac{d \\ell}{dp} = 0$, we obtain the maximum likelihood estimator:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hat p = \\frac{1}{n}\\sum_{i=1}^{n}X_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fisher information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the defintion of Fisher information is (for a single observation, i.e. $n=1$ and let $\\sum_{i=1}^nX_i = x$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$I_{\\theta} = \\mathbb{E}_{\\theta}[\\nabla \\ell(\\theta) \\nabla(\\theta)^T] = -\\mathbb{E}_{\\theta}[\\nabla^2 \\ell(\\theta)]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Ber($p$),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\frac{d \\ell}{dp} \n",
    "&= \\frac{x}{p} - \\frac{1}{1-p} + \\frac{x}{1-p} \\\\\n",
    "&= \\frac{x}{p} + \\frac{x - 1}{1-p} \\\\\n",
    "\\frac{d^2 \\ell}{dp^2} \n",
    "&= - \\frac{x}{p^2} + \\frac{x-1}{(1-p)^2} \n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we'll calculate Fisher information using both formulas ($\\mathbb{E}[\\nabla \\ell(\\theta) \\nabla(\\theta)^T]$ and $-\\mathbb{E}[\\nabla^2 \\ell(\\theta)]$), and show that they are equal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the second formula,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "I_p &= - \\mathbb{E}_{\\theta}\\Big[\\frac{d^2 \\ell}{dp^2}\\Big] \\\\\n",
    "&= - \\Big(- \\frac{x}{p^2} + \\frac{x-1}{(1-p)^2}\\Big)_{|x=1}\\mathbb{P}[X=1] - \\Big(- \\frac{x}{p^2} + \\frac{x-1}{(1-p)^2}\\Big)_{|x=0}\\mathbb{P}[X=0] \\\\\n",
    "&= \\frac{1}{p^2} p + \\frac{1}{(1-p)^2} (1-p) \\\\\n",
    "&= \\frac{1}{p} + \\frac{1}{1-p}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the first formula, further simplifying $\\frac{d \\ell}{dp}$,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{d \\ell}{dp} = \\frac{(x - xp) + (xp - p)}{p(1-p)} = \\frac{x - p}{p(1-p)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "I_p \n",
    "&= \\mathbb{E}_{\\theta}\\Big[\\frac{d \\ell}{dp} \\frac{d \\ell}{dp}\\Big] \\\\\n",
    "&= \\mathbb{E}_{\\theta}\\Big[\\frac{(x-p)^2}{p^2(1-p)^2}\\Big] \\\\\n",
    "&= \\frac{1}{p^2} p + \\frac{1}{(1-p)^2}(1-p) \\\\\n",
    "&= \\frac{1}{p} + \\frac{1}{(1-p)}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So they lead to the same result. Note $I_p$ could be further simplified to \n",
    "\n",
    "$$I_p = \\frac{1}{pq}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Poisson distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here afterwards, the logic will be exactly the same as above, but simplified. When there is no amiguity, we'll use $\\sum$ and $\\prod$ instead of $\\sum_{i=1}^n$ and $\\prod_{i=1}^n$ to avoid clutter. We'll use the same set of symbols except for the parameters of interest, e.g. $p$ for Bernoulii, $\\lambda$ for Poisson, $\\mu$ and $\\sigma^2$ for normal distributions. Parameters of interest are generally referred to as $\\theta$ when no particular distribution is specified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maximum likelihood estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\mathbb{P}_{\\lambda}[X=x] \n",
    "&= e^{-\\lambda}\\frac{\\lambda ^x}{x!}, \\;\\;\\; \\forall x \\in \\mathbb{N} \\\\\n",
    "L\n",
    "&= \\prod e^{-\\lambda}\\frac{\\lambda^{X_i}}{X_i!} \\\\\n",
    "&= e^{-n\\lambda} \\prod \\frac{\\lambda^{X_i}}{X_i!} \\\\\n",
    "\\ell\n",
    "&= \\log L \\\\\n",
    "&= -n\\lambda + \\sum X_i \\log \\lambda - \\sum \\log X_i! \\\\\n",
    "&= -n\\lambda + \\log \\lambda \\sum X_i - \\sum \\log X_i! \\\\\n",
    "\\frac{d \\ell}{d\\lambda}\n",
    "&= -n + \\frac{1}{\\lambda}\\sum X_i \n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set $\\frac{d \\ell}{d\\lambda} = 0$, we obtain,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hat \\lambda = \\frac{1}{n}\\sum X_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fisher information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a single observation,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\frac{d \\ell}{d\\lambda}\n",
    "&= -1 + \\frac{x}{\\lambda} \\\\\n",
    "\\frac{d^2 \\ell}{d\\lambda^2}\n",
    "&= -\\frac{x}{\\lambda^2}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "I_{\\lambda} \n",
    "&= -\\mathbb{E}_{\\theta}\\Big[-\\frac{x}{\\lambda^2}\\Big] \\\\\n",
    "&= \\frac{1}{\\lambda^2}\\mathbb{E}_{\\theta}[x] \\\\\n",
    "&= \\frac{1}{\\lambda} \\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Exponential distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maximum likelihood estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "f_{\\lambda}(x)\n",
    "&= \\lambda e^{-\\lambda x}, \\;\\;\\; \\forall x > 0 \\\\\n",
    "L\n",
    "&= \\prod \\lambda e^{-\\lambda X_i} \\\\\n",
    "&= \\lambda^n e^{-\\lambda \\sum X_i} \\\\\n",
    "\\ell\n",
    "&= \\log L \\\\\n",
    "&= n\\log \\lambda - \\lambda \\sum X_i \\\\\n",
    "\\frac{d \\ell}{d\\lambda}\n",
    "&= \\frac{n}{\\lambda} - \\sum X_i\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set $\\frac{d \\ell}{d\\lambda} = 0$, we obtain,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hat \\lambda = \\frac{n}{\\sum X_i}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fisher information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a single observation,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\frac{d \\ell}{d\\lambda}\n",
    "&= \\frac{1}{\\lambda} - x \\\\\n",
    "\\frac{d^2 \\ell}{d\\lambda^2}\n",
    "&= -\\frac{1}{\\lambda^2}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "I_{\\lambda} \n",
    "&= -\\mathbb{E}_{\\theta}\\Big[-\\frac{1}{\\lambda^2}\\Big] \\\\\n",
    "&= \\frac{1}{\\lambda^2} \\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Gaussian distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maximum likelihood estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "f_{\\mu, \\sigma^2}(x)\n",
    "&= \\frac{1}{\\sqrt{2 \\pi \\sigma^2}}\\exp\\Big({-\\frac{(x-\\mu)^2}{2\\sigma^2}}\\Big) \\\\\n",
    "L\n",
    "&= \\prod \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\exp\\Big({-\\frac{(X_i-\\mu)^2}{2\\sigma^2}}\\Big) \\\\\n",
    "&= (2\\pi)^{-\\frac{n}{2}} (\\sigma^2)^{-\\frac{n}{2}} \\exp\\Big(-\\sum {\\frac{(X_i-\\mu)^2}{2\\sigma^2}}\\Big)\\\\\n",
    "\\ell\n",
    "&= \\log L \\\\\n",
    "&= -\\frac{n}{2}\\log 2\\pi - \\frac{n}{2}\\log \\sigma^2 - \\frac{1}{2\\sigma^2}\\sum {(X_i-\\mu)^2} \\\\\n",
    "\\frac{\\partial \\ell}{\\partial \\mu} \n",
    "&= \\frac{1}{\\sigma^2}\\sum (X_i - \\mu) \\\\\n",
    "\\frac{\\partial \\ell}{\\partial \\sigma^2} \n",
    "&= - \\frac{n}{2\\sigma^2} + \\frac{1}{2(\\sigma^2)^2}\\sum (X_i - \\mu)^2 \\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set $\\frac{d \\ell}{d\\mu} = 0$, we obtain,\n",
    "\n",
    "$$ \\hat \\mu = \\frac{1}{n}\\sum X_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set $\\frac{d \\ell}{d\\sigma^2} = 0$, we obtain,\n",
    "\n",
    "$$ \\hat \\sigma^2 = \\frac{1}{n}\\sum (X_i - \\mu)^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fisher information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a single observation,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\frac{\\partial \\ell}{\\partial \\mu}\n",
    "&= \\frac{x - \\mu}{\\sigma^2} \\\\\n",
    "\\frac{\\partial \\ell}{\\partial \\sigma^2}\n",
    "&= -\\frac{1}{2\\sigma^2} + \\frac{(x-\\mu)^2}{2\\sigma^4} \\\\\n",
    "&= \\frac{(x - \\mu)^2 - \\sigma^2}{2 \\sigma^4} \n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\theta = [\\mu, \\sigma^2]^T$,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\nabla^2\\ell(\\theta)\n",
    "&= \\begin{bmatrix}\n",
    "\\frac{\\partial^2 \\ell}{\\partial \\mu^2} & \\frac{\\partial^2 \\ell}{\\partial \\mu \\partial \\sigma^2}\\\\ \n",
    "\\frac{\\partial^2 \\ell}{\\partial \\sigma^2 \\partial \\mu} & \\frac{\\partial^2 \\ell}{\\partial (\\sigma^2)^2}\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "- \\frac{1}{\\sigma^2} & \\frac{\\mu - x}{(\\sigma^2)^2}\\\\ \n",
    "\\frac{\\mu - x}{(\\sigma^2)^2} & \\frac{1}{2 (\\sigma^2)^2} - \\frac{(x-\\mu)^2}{(\\sigma^2)^3}\n",
    "\\end{bmatrix} \\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "I_{\\theta} \n",
    "&= -\\mathbb{E}_{\\theta}\\big[\\nabla^2\\ell(\\theta)\\big] \\\\\n",
    "&= - \\begin{bmatrix}\n",
    "\\mathbb{E}_{\\theta}\\Big[- \\frac{1}{\\sigma^2}\\Big] & \\mathbb{E}_{\\theta}\\Big[\\frac{\\mu - x}{(\\sigma^2)^2} \\Big]\\\\ \n",
    "\\mathbb{E}_{\\theta}\\Big[\\frac{\\mu - x}{(\\sigma^2)^2}\\Big] & \\mathbb{E}_{\\theta}\\Big[\\frac{1}{2 (\\sigma^2)^2} - \\frac{(x-\\mu)^2}{(\\sigma^2)^3} \\Big]\n",
    "\\end{bmatrix} \\\\\n",
    "&= - \\begin{bmatrix}\n",
    "- \\frac{1}{\\sigma^2} & 0 \\\\ \n",
    "0 & - \\frac{1}{2(\\sigma^2)^2}\n",
    "\\end{bmatrix} \\\\\n",
    "&= \\begin{bmatrix}\n",
    "\\frac{1}{\\sigma^2} & 0 \\\\ \n",
    "0 & \\frac{1}{2(\\sigma^2)^2}\n",
    "\\end{bmatrix} \\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note $x$ is the random variable, so recognizing $\\mathbb{E}_{\\theta}(x-\\mu) = 0$, and $\\mathbb{E}_{\\theta}(x-\\mu)^2 = \\sigma^2$ makes the calculation more straightforward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Shifted exponential distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maximum likelihood estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "f_{\\lambda, a}(x)\n",
    "&= \\lambda e^{-\\lambda (x - a)} \\mathbb{1}_{x \\ge a}, \\;\\;\\; \\forall x \\in \\mathbb{R} \\\\\n",
    "L\n",
    "&= \\prod \\lambda e^{-\\lambda (X_i - a)} \\\\\n",
    "&= \\lambda^n e^{-\\lambda \\sum(X_i - a)} \\\\\n",
    "\\ell\n",
    "&= \\log L \\\\\n",
    "&= n\\log \\lambda -\\lambda \\sum (X_i -a) \\\\\n",
    "&= n\\log \\lambda -\\lambda \\sum X_i + n\\lambda a) \\\\\n",
    "\\frac{\\partial \\ell}{\\partial \\lambda} \n",
    "&= \\frac{n}{\\lambda} - \\sum (X_i -a) \\\\\n",
    "\\frac{\\partial \\ell}{\\partial a}\n",
    "&= n\\lambda  \n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting $\\frac{\\partial \\ell}{\\partial \\lambda} = 0$,\n",
    "\n",
    "$$ \\hat \\lambda = \\frac{n}{\\sum (X_i - a)}$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since $\\frac{\\partial \\ell}{\\partial a}$ is always positive, and $\\ell$ is a linear function of $a$ with a positive slope $n\\lambda$, so $\\ell$ is monotonically increasing in $a$. Therefore, to maximize $a$ under the constraint that $a \\le x$,\n",
    "\n",
    "$$ a = \\min(X_1, \\cdots, X_n)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fisher information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a single observation,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\frac{\\partial \\ell}{\\partial \\lambda} \n",
    "&= \\frac{1}{\\lambda} - (x -a) \\\\\n",
    "\\frac{\\partial \\ell}{\\partial a}\n",
    "&= \\lambda  \n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\theta = [\\lambda, a]^T$,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\nabla^2\\ell(\\theta)\n",
    "&= \\begin{bmatrix}\n",
    "\\frac{\\partial^2 \\ell}{\\partial \\lambda^2} & \\frac{\\partial^2 \\ell}{\\partial \\lambda \\partial a}\\\\ \n",
    "\\frac{\\partial^2 \\ell}{\\partial a \\partial \\lambda} & \\frac{\\partial^2 \\ell}{\\partial \\lambda^2}\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "- \\frac{1}{\\lambda^2} & 1\\\\ \n",
    "1 & 0\n",
    "\\end{bmatrix} \\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "I_{\\theta} \n",
    "&= -\\mathbb{E}_{\\theta}\\big[\\nabla^2\\ell(\\theta)\\big] \n",
    "= \\begin{bmatrix}\n",
    "\\frac{1}{\\lambda^2} & -1 \\\\ \n",
    "-1 & 0\n",
    "\\end{bmatrix} \\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note $\\nabla^2\\ell(\\theta)$ doesn't depend on $x$, so its expectation is just itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Log-normal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maximum likelihood estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "f_{\\mu, \\sigma^2}(x)\n",
    "&= \\frac{1}{x\\sqrt{2\\pi\\sigma^2}}\\exp\\Big(-\\frac{1}{2\\sigma^2}(\\ln x - \\mu)^2\\Big), \\;\\;\\; \\forall x > 0 \\\\\n",
    "L\n",
    "&= \\prod \\frac{1}{X_i\\sqrt{2\\pi\\sigma^2}}\\exp\\Big(-\\frac{1}{2\\sigma^2}(\\ln X_i - \\mu)^2\\Big) \\\\\n",
    "&= \\big(2\\pi\\sigma^2 \\big)^{-\\frac{n}{2}} \\big(\\prod X_i\\big)^{-1} \\exp\\Big(-\\frac{1}{2\\sigma^2} \\sum (\\ln X_i - \\mu)^2 \\Big)\\\\\n",
    "\\ell\n",
    "&= \\log L \\\\\n",
    "&= -\\frac{n}{2} \\log 2 \\pi - \\frac{n}{2}\\log \\sigma^2  - \\sum X_i - \\frac{1}{2\\sigma^2} \\sum (\\ln X_i - \\mu)^2 \\\\\n",
    "\\frac{\\partial \\ell}{\\partial \\mu} \n",
    "&= \\frac{1}{\\sigma^2} \\sum (\\ln X_i - \\mu) \\\\\n",
    "\\frac{\\partial \\ell}{\\partial \\sigma^2}\n",
    "&= -\\frac{n}{2\\sigma^2} + \\frac{1}{2 (\\sigma^2)^2}  \\sum (\\ln X_i - \\mu)^2\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting $\\frac{\\partial \\ell}{\\partial \\mu} = 0$ and $\\frac{\\partial \\ell}{\\partial \\sigma^2} = 0$, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\hat \\mu\n",
    "&= \\frac{\\sum \\ln X_i}{n} \\\\\n",
    "\\hat \\sigma^2\n",
    "&= \\frac{\\sum (\\ln X_i - \\mu)^2}{n}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fisher information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a single observation,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\frac{\\partial \\ell}{\\partial \\mu}\n",
    "&= \\frac{\\ln x - \\mu}{\\sigma^2} \\\\\n",
    "\\frac{\\partial \\ell}{\\partial \\sigma^2}\n",
    "&= -\\frac{1}{2\\sigma^2} + \\frac{(\\ln x-\\mu)^2}{2\\sigma^4}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\theta = [\\mu, \\sigma^2]^T$,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\nabla^2\\ell(\\theta)\n",
    "&= \\begin{bmatrix}\n",
    "\\frac{\\partial^2 \\ell}{\\partial \\mu^2} & \\frac{\\partial^2 \\ell}{\\partial \\mu \\partial \\sigma^2}\\\\ \n",
    "\\frac{\\partial^2 \\ell}{\\partial \\sigma^2 \\partial \\mu} & \\frac{\\partial^2 \\ell}{\\partial (\\sigma^2)^2}\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "- \\frac{1}{\\sigma^2} & \\frac{\\mu - \\ln x}{(\\sigma^2)^2}\\\\ \n",
    "\\frac{\\mu - \\ln x}{(\\sigma^2)^2} & \\frac{1}{2 (\\sigma^2)^2} - \\frac{(\\ln x-\\mu)^2}{(\\sigma^2)^3}\n",
    "\\end{bmatrix} \\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "I_{\\theta} \n",
    "&= -\\mathbb{E}_{\\theta}\\big[\\nabla^2\\ell(\\theta)\\big] \\\\\n",
    "&= - \\begin{bmatrix}\n",
    "\\mathbb{E}_{\\theta}\\Big[- \\frac{1}{\\sigma^2}\\Big] & \\mathbb{E}_{\\theta}\\Big[\\frac{\\mu - \\ln x}{(\\sigma^2)^2} \\Big]\\\\ \n",
    "\\mathbb{E}_{\\theta}\\Big[\\frac{\\mu - \\ln x}{(\\sigma^2)^2}\\Big] & \\mathbb{E}_{\\theta}\\Big[\\frac{1}{2 (\\sigma^2)^2} - \\frac{(\\ln x-\\mu)^2}{(\\sigma^2)^3} \\Big]\n",
    "\\end{bmatrix} \\\\\n",
    "&= - \\begin{bmatrix}\n",
    "- \\frac{1}{\\sigma^2} & 0 \\\\ \n",
    "0 & - \\frac{1}{2(\\sigma^2)^2}\n",
    "\\end{bmatrix} \\\\\n",
    "&= \\begin{bmatrix}\n",
    "\\frac{1}{\\sigma^2} & 0 \\\\ \n",
    "0 & \\frac{1}{2(\\sigma^2)^2}\n",
    "\\end{bmatrix} \\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarks:\n",
    "\n",
    "* Since $\\ln x \\sim \\mathcal{N}(\\mu, \\sigma^2)$ (by definition of log-normal distribution), $\\mathbb{E}_{\\theta}[\\mu - \\ln x] = 0$, and $\\mathbb{E}_{\\theta}[(\\ln x - \\mu)^2] = \\sigma^2$.\n",
    "* The Fisher information matrix of log-normal distribution is the same as that of normal (Gaussian) distribution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
